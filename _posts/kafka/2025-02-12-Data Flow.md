---
title: Data Flow
category: Kafka
tag: [Kafka]
---

> Kafka는 분산 메시지 시스템으로, 프로듀서가 데이터를 파티션에 분배하고, 컨슈머가 그 데이터를 읽는 방식으로 메시지를 전달합니다. 프로듀서는 메시지를 파티션에 전송할 때 키 기반 파티셔닝 또는 라운드로빈 방식으로 데이터를 분배하며, 컨슈머는 파티션의 오프셋을 통해 데이터를 읽고, 이를 처리한 후 오프셋을 커밋하여 메시지의 순서와 중복 처리 문제를 관리합니다

---

## Producer
`Producer`는 데이터를 **토픽(topic)**에 전송하며, 카프카는 이를 **파티션(partition)**에 분배합니다. 기본적으로 메시지의 **키(key)**를 기준으로 파티션을 결정하고, 키가 없으면 **라운드로빈(round-robin)** 방식으로 선택합니다. 각 파티션은 메시지를 **오프셋(offset)** 번호로 구분해 순서를 관리합니다.

[![](\assets\posts\2025-02-12-Data Flow\producer.png)](\assets\posts\2025-02-12-Data Flow\producer.png)

### Hash-based
해시 값을 기반으로 파티션을 결정하는 방식입니다. 프로듀서가 메시지에 포함된 키를 해싱하여 그 값을 바탕으로 특정 파티션을 선택합니다. 같은 키는 항상 같은 파티션에 저장되므로, 동일한 데이터를 여러 번 처리할 때 일관된 처리가 가능합니다.

```python
from kafka import KafkaProducer

# Kafka 프로듀서 설정
producer = KafkaProducer(bootstrap_servers='localhost:9092', 
                         key_serializer=str.encode, 
                         value_serializer=str.encode)

# 메시지 보내기 (키 기반 파티셔닝)
key = "user-1"
value = "Message for user-1"
producer.send('user_topic', key=key, value=value)

# 전송 완료 후 종료
producer.flush()
producer.close()
```

### Round-robin
라운드로빈 방식은 파티션에 데이터를 균등하게 분배하는 방법입니다. 프로듀서는 메시지를 순차적으로 각 파티션에 전송하며, 키가 없는 경우 기본적으로 이 방식을 사용합니다. 이 방식은 데이터 분배가 균등하게 이루어져 부하 분산이 잘 됩니다.

```python
from kafka import KafkaProducer

# Kafka 프로듀서 설정
producer = KafkaProducer(bootstrap_servers='localhost:9092', 
                         key_serializer=str.encode, 
                         value_serializer=str.encode)

# 메시지 보내기 (키 없는 경우)
value = "Message without key"
producer.send('user_topic', value=value)

# 전송 완료 후 종료
producer.flush()
producer.close()
```

---

## Consumer
`Consumer`는 지정된 토픽과 파티션에서 데이터를 읽습니다. 이때 중요한 것이 **오프셋(offset)**으로, 이는 파티션 내 메시지의 위치를 나타내며, 메시지를 읽을 때마다 오프셋은 자동으로 증가하고, 성공적으로 처리된 메시지는 **커밋(commit)**되어 저장됩니다. 커밋된 오프셋을 통해, 컨슈머는 다음에 데이터를 어디서부터 읽을지 알 수 있습니다.

[![](\assets\posts\2025-02-12-Data Flow\consumer.png)](\assets\posts\2025-02-12-Data Flow\consumer.png)

### Auto Commit
카프카는 기본적으로 일정 주기마다 자동으로 오프셋을 커밋합니다. 이는 간단하지만, 컨슈머가 처리 중인 메시지가 커밋되기 전에 실패할 경우 메시지가 중복으로 처리될 위험이 있습니다.

```python
from kafka import KafkaConsumer

# Kafka 컨슈머 설정
consumer = KafkaConsumer('user_topic',
                         group_id='test-consumer-group',
                         bootstrap_servers='localhost:9092',
                         key_deserializer=bytes.decode,
                         value_deserializer=bytes.decode)

# 메시지 읽기
for message in consumer:
    print(f"Received message: {message.value} at offset {message.offset}")
```

### Manual Commit
수동 커밋을 설정하면, 컨슈머는 메시지를 처리한 후에 오프셋을 명시적으로 커밋해야 합니다. 이 방식은 실패 시 메시지를 중복 처리하지 않도록 보장할 수 있지만, 커밋을 적절히 관리하는 로직이 필요합니다.

```python
from kafka import KafkaConsumer

# Kafka 컨슈머 설정 (자동 커밋 비활성화)
consumer = KafkaConsumer('user_topic',
                         group_id='manual-commit-group',
                         bootstrap_servers='localhost:9092',
                         enable_auto_commit=False,  # 자동 커밋 비활성화
                         key_deserializer=bytes.decode,
                         value_deserializer=bytes.decode)

# 메시지 읽기 및 오프셋 수동 커밋
for message in consumer:
    print(f"Received message: {message.value} at offset {message.offset}")

    # 수동으로 오프셋 커밋
    consumer.commit()
```

---

## References
- [Kafka 공식 문서](https://spark.apache.org/docs/latest/)

<nav class="post-toc" markdown="1">
  <h2>Contents</h2>
* TOC
{:toc}
</nav>
